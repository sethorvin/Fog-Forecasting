"""
This script assumes that processed_data_china_winter2024.csv has been
generated by feature_engineering.py

This script implements hyperparameter tuning for a Random Forest estimator to train a
RF model on the best set of parameters. This trained model is then saved to a .pkl model
to be loaded at a later time.
Seth Orvin
"""

import pandas as pd
import numpy as np
import os
import sys
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import classification_report, roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns

# Get the path to the data directory, relative to this script
script_dir = os.path.dirname(os.path.abspath(__file__))
data_path = os.path.join(script_dir, '..', 'data', 'processed_data_china_winter2024.csv')

# Attempt to load data into a DataFrame, exit otherwise
if os.path.exists(data_path):
    try:
        df = pd.read_csv(data_path, parse_dates=['time'], low_memory=False)
        df.sort_values(by=['station', 'time'], inplace=True)
    except Exception as e:
        print('Error loading processed data file: {e}')
        sys.exit(1)
else:
    print(f'File not found at {data_path}')
    sys.exit(1)

# Create binary fog label (1 if fog, 0 otherwise)
df['is_fog'] = df['coco'].isin([5, 6]).astype(int) # https://dev.meteostat.net/formats.html#weather-condition-codes

# Create target for forecasting: Was there fog 1 hour later?
df['is_fog_in_1h'] = df.groupby('station')['is_fog'].shift(-1)

# Drop rows with missing target
df = df.dropna(subset=['is_fog_in_1h'])
df['is_fog_in_1h'] = df['is_fog_in_1h'].astype(int)

# Define features and target
features = [
    'd2m', 't2m', 'sp', 'lcc', 'tcc', 'swvl1', 'blh',
    'latitude', 'longitude', 'wind_speed', 'relative_humidity',
]
target = 'is_fog_in_1h'

# Split data into training and test sets (only use first 80% of data for splitting,
# want to leave 20% completely unseen for later simulations/"forecasting")
split_index = int(len(df) * 0.8)
df = df.iloc[:split_index]
X = df[features]
y = df[target]

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Parameter distribution for hyperparameter tuning
param_dist = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2'],
    'class_weight': ['balanced']
}

# Use hyperparameter tuning to search for best RF estimator
rf = RandomForestClassifier(random_state=42)
search = RandomizedSearchCV(rf, param_distributions=param_dist,
                            scoring='roc_auc', cv=5, n_iter=20, verbose=2, n_jobs=-1)
search.fit(X_train, y_train)

# Save the best estimator for later use
best_rf = search.best_estimator_
joblib.dump(best_rf, 'best_random_forest_model.pkl')

print("Best parameters:", search.best_params_)
# Best parameters: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'class_weight': 'balanced'}


"""
# Test Code to Produce Classification Report and View Feature Importance Plot
# Train Random Forest
best_rf = RandomForestClassifier(
    n_estimators=300,
    min_samples_split=5,
    min_samples_leaf=1,
    max_features='sqrt',
    max_depth=None,
    class_weight='balanced',
    random_state=42,
)
best_rf.fit(X_train, y_train)

# Evaluate
y_pred = best_rf.predict(X_test)
y_prob = best_rf.predict_proba(X_test)[:, 1]

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print(f"ROC AUC Score: {roc_auc_score(y_test, y_prob):.3f}")


# Get feature importances and feature names
importances = best_rf.feature_importances_
feature_names = X_train.columns

# Create a DataFrame for easy plotting
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

# Plot
plt.figure(figsize=(10, 6))
sns.barplot(data=importance_df, x='Importance', y='Feature', palette='viridis')
plt.title('Feature Importance (Random Forest)')
plt.tight_layout()
plt.show()
"""